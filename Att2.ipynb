{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ec1a4-73e0-427a-9864-53cb8fd474fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe\n",
    "!pip install tensorflow\n",
    "!pip install kaggle\n",
    "!kaggle datasets download -d grassknoted/asl-alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ad6af-10f7-4d29-a77e-9d8f2eb40d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patoolib\n",
    "patoolib.extract_archive(\"asl-alphabet.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843882c2-084d-4f0f-88fa-fb1c968ec9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.5.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd0f468-c4b9-41b7-862b-2aa61a71eadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87000 files belonging to 29 classes.\n",
      "Using 69600 files for training.\n",
      "Found 87000 files belonging to 29 classes.\n",
      "Using 17400 files for validation.\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "path_Train = \"C:/HackWesTX/asl_alphabet_train/asl_alphabet_train\"\n",
    "data_dir = Path(path_Train)\n",
    "batch_size = 100\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7377d34a-b867-4481-9e3c-5c7dcf02910e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#defining the model\n",
    "\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# number of possible label values\n",
    "nb_classes = 29\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(nb_classes)\n",
    "])\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f2fbf0-06f4-4e1b-aa6a-cfc42c98a192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "696/696 [==============================] - 121s 174ms/step - loss: 1.2546 - accuracy: 0.6280 - val_loss: 1.1615 - val_accuracy: 0.6548\n",
      "Epoch 2/15\n",
      "696/696 [==============================] - 121s 174ms/step - loss: 1.0676 - accuracy: 0.6819 - val_loss: 1.0134 - val_accuracy: 0.6918\n",
      "Epoch 3/15\n",
      "696/696 [==============================] - 125s 180ms/step - loss: 0.9277 - accuracy: 0.7221 - val_loss: 0.9135 - val_accuracy: 0.7251\n",
      "Epoch 4/15\n",
      "696/696 [==============================] - 131s 188ms/step - loss: 0.8185 - accuracy: 0.7552 - val_loss: 0.7959 - val_accuracy: 0.7589\n",
      "Epoch 5/15\n",
      "696/696 [==============================] - 130s 187ms/step - loss: 0.7270 - accuracy: 0.7810 - val_loss: 0.7303 - val_accuracy: 0.7784\n",
      "Epoch 6/15\n",
      "696/696 [==============================] - 129s 184ms/step - loss: 0.6527 - accuracy: 0.8032 - val_loss: 0.6481 - val_accuracy: 0.7993\n",
      "Epoch 7/15\n",
      "696/696 [==============================] - 129s 185ms/step - loss: 0.5843 - accuracy: 0.8249 - val_loss: 0.5760 - val_accuracy: 0.8239\n",
      "Epoch 8/15\n",
      "696/696 [==============================] - 119s 170ms/step - loss: 0.5282 - accuracy: 0.8424 - val_loss: 0.5332 - val_accuracy: 0.8330\n",
      "Epoch 9/15\n",
      "696/696 [==============================] - 114s 163ms/step - loss: 0.4807 - accuracy: 0.8554 - val_loss: 0.4871 - val_accuracy: 0.8482\n",
      "Epoch 10/15\n",
      "696/696 [==============================] - 113s 163ms/step - loss: 0.4356 - accuracy: 0.8699 - val_loss: 0.4381 - val_accuracy: 0.8655\n",
      "Epoch 11/15\n",
      "696/696 [==============================] - 106s 153ms/step - loss: 0.3977 - accuracy: 0.8803 - val_loss: 0.4177 - val_accuracy: 0.8695\n",
      "Epoch 12/15\n",
      "696/696 [==============================] - 107s 154ms/step - loss: 0.3663 - accuracy: 0.8896 - val_loss: 0.3678 - val_accuracy: 0.8873\n",
      "Epoch 13/15\n",
      "696/696 [==============================] - 107s 153ms/step - loss: 0.3327 - accuracy: 0.9008 - val_loss: 0.3456 - val_accuracy: 0.8952\n",
      "Epoch 14/15\n",
      "696/696 [==============================] - 115s 164ms/step - loss: 0.3080 - accuracy: 0.9066 - val_loss: 0.3188 - val_accuracy: 0.9048\n",
      "Epoch 15/15\n",
      "696/696 [==============================] - 111s 160ms/step - loss: 0.2827 - accuracy: 0.9166 - val_loss: 0.2971 - val_accuracy: 0.9095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e442b53f70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=val_ds,epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82381eaf-829c-4315-b899-1ffd09dd55c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: asl.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"asl.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
